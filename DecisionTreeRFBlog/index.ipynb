{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  echo: fenced\n",
        "title: Comparing Decision Tree and Random Forest Classifier\n",
        "toc: true\n",
        "toc-title: Table of contents\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true\n",
        "    code-copy: true\n",
        "    code-link: true\n",
        "    code-tools: true\n",
        "    theme:\n",
        "      dark: darkly\n",
        "      light: flatly\n",
        "    pdf:\n",
        "      title: DecisionTreeAndRF\n",
        "      author: Daniel Hassler\n",
        "      pdf-engine: 'C:/Program Files (x86)/wkhtmltopdf'\n",
        "  docx: default\n",
        "  ipynb: default\n",
        "  gfm: default\n",
        "filters:\n",
        "  - social-share\n",
        "share:\n",
        "  permalink: 'https://hassledw.github.io/DecisionTreeRFBlog/'\n",
        "  description: Comparing RandomForestClassifier and DecisionTreeClassifier on BMI data\n",
        "  twitter: true\n",
        "  facebook: true\n",
        "  reddit: true\n",
        "  stumble: false\n",
        "  tumblr: false\n",
        "  linkedin: true\n",
        "  email: true\n",
        "---"
      ],
      "id": "0cf768e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- title: \"Comparing Decision Tree and Random Forest Classifier Performance\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "jupyter: python3 -->\n",
        "**Author: Daniel Hassler**\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./index.css\">\n",
        "<div class=\"social-icons\">\n",
        "  <a href=\"https://github.com/hassledw\"><i class=\"fab fa-github\"></i></a>\n",
        "  <a href=\"https://www.linkedin.com/in/daniel-hassler-85027a21a/\"><i class=\"fab fa-linkedin\"></i></a>\n",
        "  <!-- Add more social media links/icons as needed -->\n",
        "</div>\n",
        "\n",
        "## Sample Data Used in Classification\n",
        "To compare a DecisionTree and a RandomForestClassifier, the first step I took was to gather some data and run some visualizations and analysis. Through Kaggle, I was able to obtain a small dataset on person features and their BMI (Body Mass Index) data. The data consists of just around 400 samples with features: gender, height, and weight, and the goal is to predict BMI. \n"
      ],
      "id": "1f1a762d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, learning_curve, LearningCurveDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "5554c63a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.read_csv(\"./datasets/bmi_train.csv\")\n",
        "category_mapping = {'Male': 0, 'Female': 1}\n",
        "data['Gender_Encoded'] = data['Gender'].map(category_mapping) # converts categorical data to numeric data.\n",
        "X = data.drop(['Gender','Index'], axis=1)\n",
        "y = data.drop(['Gender', 'Gender_Encoded', 'Height', 'Weight'], axis=1)\n",
        "print(\"All X shape: \", X.shape)\n",
        "print(\"All y shape: \", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "id": "03ba395a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the above code snippet, I first populated my data into a Pandas dataframe and then split up the data into a \"training\" and \"testing\" datasets. I decided to go with an 80/20% split between train and test (with its corresponding labels), as that seems to be the most standard approach in the industry. The significant benefit here is that I possess labeled data on both sets, a challenge in practice. This enables me to make comparisons between predictions and outcomes on my data, eliminating the need to procure any additional \"test\" data.\n"
      ],
      "id": "4e855ec0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(data=data, x='Height', y='Weight', hue='Index', palette='deep')\n",
        "plt.title('Scatter Plot of Height vs Weight')\n",
        "plt.show()"
      ],
      "id": "9bf631a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I created a scatterplot showing the distribution of the entire dataset (n=400) to find linear associations. Based on the scatterplot above, I was roughly able to see that there was a class imbalance. \n"
      ],
      "id": "76e838f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Class imbalance, more obesity.\n",
        "unique_values, counts = np.unique(y, return_counts=True)\n",
        "plt.bar(unique_values, counts)\n",
        "plt.title(\"BMI Classes in the Entire Dataset\")\n",
        "plt.xlabel(\"BMI Class\")\n",
        "plt.ylabel(\"Occurences in Entire Dataset\")\n",
        "plt.show()"
      ],
      "id": "7043cbe6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The labels are all discrete and sequential, consisting of whole numbers between 0 and 5, further enforcing my intuition for using a classifier approach. A \"0\" in my case represents someone with an **exeptionally low** BMI, whereas a \"5\" depicts an **exceptionally high** BMI. Based on the distribution of the data, there appears to be a huge class imbalance, heavily favoring the amount of **exceptionally high** instances in the dataset; this was something I needed to keep in mind when building the classifiers for this dataset.\n"
      ],
      "id": "3fb48cc0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "correlation_matrix = data.corr()\n",
        "\n",
        "# Display a heatmap of the correlation matrix\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "id": "9e21d47e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation matrix depicts the correlation between features (height, weight, gender, BMI) in the dataset. It uses the pearson's correlation coefficient to compute this:\n",
        "$$\n",
        " r =\n",
        "  \\frac{ \\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{\n",
        "        \\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}}\n",
        "$$\n",
        "\n",
        "Based on the features presented, most are not correlated strongly, but there is a glaring strong correlation between weight and BMI. It is also important to note that `gender` doesn't influence classification results, as the key factors to determining BMI is height and weight. \n",
        "\n",
        "## DecisionTreeClassifier\n",
        "\n",
        "In order to start the model building process, I decided to tune the hyperparamters first by running a `GridSearch`\n"
      ],
      "id": "ee3a8fe9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "param_grid = {\n",
        "    'max_depth': [i for i in range(2, 6)],\n",
        "    'min_samples_leaf': [2 ** i for i in range(0, 6)],\n",
        "    'criterion': [\"entropy\", \"gini\"]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "grid_search_dt = GridSearchCV(dt, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
        "grid_search_dt.fit(X_train, y_train)\n",
        "best_params_dt = grid_search_dt.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params_dt)\n",
        "print(\"Best Score:\", grid_search_dt.best_score_)"
      ],
      "id": "f5f50206",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I recognized that `max_depth` was an important hyperparameter for the DecisionTree (DT), as the depth of the tree heavily influences overfitting, but other hyperparameters are important as well, such as:\n",
        "\n",
        "* `min_samples_leaf`: the minimum amount of samples needed in a leaf node of the DT. For example, when min_samples_leaf is set to 10, that means a node won't split if it has fewer than 10 samples. When this number is higher, the model can create a more generalized tree, although, when the number is smaller, it'll create more specific splits, resulting in a more complex tree (more potential for overfitting).\n",
        "\n",
        "* `criterion`: this hyperparameter chooses whether to use entropy or Gini index as a way to calculate dissimilarity in a node. I found that in most cases, entropy outpreformed the Gini index.\n",
        "$$\n",
        "Entropy(C) = -\\sum_{c=1}^Cp(c)\\log(p(c))\n",
        "$$\n",
        "\n",
        "$$\n",
        "Gini(C) = 1 - \\sum_{c=1}^Cp(c)^2\n",
        "$$\n",
        "\n",
        "Now that I've determined the necessary hyperparameters for this classifier, I initialize the `GridSearchCV` object to analyze every combination of the above hyperparameters. Within its search, it goes through an important cross-validation step (cv) that splits the training data into multiple folds and iterates through each fold for each hyperparameter combination.\n",
        "\n",
        "There were a few options I could've chose from for the cv parameter in `GridSearchCV`, but in order to account for class imbalance like I stated earlier, I decided to go with a `StratifiedKFold` cross-validator. StratifiedKFold accounts for class label imbalance by keeping an equal precentage of classes for training and testing represented in the dataset. Below is a picture representing this:\n",
        "\n",
        "<img style=\"display: block;\n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\"\n",
        "    height=\"300\" width=\"300\" src=\"https://amueller.github.io/aml/_images/stratified_cv.png\"></img>\n"
      ],
      "id": "38c9ac4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dt = DecisionTreeClassifier(max_depth=best_params_dt[\"max_depth\"], min_samples_leaf=best_params_dt[\"min_samples_leaf\"], criterion=best_params_dt[\"criterion\"])\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)"
      ],
      "id": "81231750",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I then created a `DecisionTreeClassifier` with the 'best' tuned hyperparameters from the above grid search and populated the `y_pred` array with the predictions from the test dataset. After that, I plotted the tree out using Sklearn's plot_tree method.\n"
      ],
      "id": "ce1bd8a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plot_tree(dt, feature_names=X_train.columns.tolist(), class_names=['0', '1', '2','3','4','5'], filled=True)\n",
        "plt.show()"
      ],
      "id": "5b5cff45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After plotting the tree, I created a confusion matrix, showing where my predictions fell. Currently, the model sits around 75-86% accurate due to the above hyperparameter values and the randomly generated tree with those hyperparameter values. Not bad for a small dataset with class imbalance.\n"
      ],
      "id": "b1825637"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Micro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Macro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))"
      ],
      "id": "7d26eef7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
        "conf_df = pd.DataFrame(confusion_matrix, index=[f\"{i}\" for i in range(6)], columns=[f\"{i}\" for i in range(6)])\n",
        "heatmap = sns.heatmap(conf_df, annot=True, fmt=\"d\", linewidths=0.35, cmap=\"YlGnBu\")\n",
        "plt.title(f\"Model Predictions With {(np.sum(confusion_matrix.diagonal()) / y_test.shape[0]) * 100:.2f}% Accuracy\")"
      ],
      "id": "19082e7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RandomForestClassifer (Ensemble approach)\n",
        "\n",
        "As above with the `DecisionTreeClassifer`, I first started to implement the `RandomForestClassifier` by tuning the hyperparameter values. Since a RandomForest is just a collection of DecisionTrees, RandomForestClassifiers, like a `DecisionTreeClassifier`, have mostly the same hyperparameters, but the `RandomForestClassifier` has an extra one for the amount of DecisionTrees that should be included in the forest (`n_estimators`).\n",
        "\n",
        "Though this step wasn't as necessary, since I already did the hyperparameter tuning part for the DecisionTree, but I decided to include it again for the RandomForest with the number of estimators.\n",
        "\n",
        "It is important to note that the `n_estimators` hyperparameter won't cause the model to overfit. In fact, it actually does better at generalization when increasing the number of estimators due to the diversity of opinions the model presents for each unique DecisionTree. The only way overfitting can happen in a RandomForest depends on how the underlying DecisionTrees are set up, not the quantity of them.\n"
      ],
      "id": "d04fb2e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "param_grid = {\n",
        "    'max_depth': [i for i in range(2, 6)],\n",
        "    'min_samples_leaf': [2 ** i for i in range(0, 6)],\n",
        "    'criterion': [\"entropy\", \"gini\"]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "print(y_train.shape)\n",
        "grid_search_rf = GridSearchCV(rf, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
        "grid_search_rf.fit(X_train, y_train.values.ravel())\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params_rf)\n",
        "print(\"Best Score:\", grid_search_rf.best_score_)"
      ],
      "id": "018b80bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf = RandomForestClassifier(n_estimators=300, \n",
        "                            max_depth=best_params_rf[\"max_depth\"], \n",
        "                            min_samples_leaf=best_params_rf[\"min_samples_leaf\"],\n",
        "                            criterion=best_params_rf[\"criterion\"])\n",
        "rf.fit(X_train, y_train.values.ravel())\n",
        "y_pred = rf.predict(X_test)"
      ],
      "id": "894ceb8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above code snippet creates the `RandomForestClassifier` with the same hyperparameters as the DecisionTree, in addition to the number of estimators (number of decision trees in the forest), trains the classifier, then stores a prediction array.\n",
        "\n",
        "Here is a visualizaiton of a subset of DecisionTrees in this RandomForest:\n"
      ],
      "id": "544de1ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    fig, axes = plt.subplots(nrows = 1,ncols = 5,figsize = (10,3), dpi=250)\n",
        "    for index in range(5):\n",
        "        tree.plot_tree(rf.estimators_[index],\n",
        "                    feature_names = X_train.columns.tolist(), \n",
        "                    class_names= [f\"{i}\" for i in range(6)],\n",
        "                    filled = True,\n",
        "                    ax = axes[index])\n",
        "\n",
        "        axes[index].set_title('Estimator: ' + str(index + 1), fontsize = 10)\n",
        "    plt.show()"
      ],
      "id": "ea83f422",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the model, I checked the accuracy output of the prediction array and found that the RandomForestClassifier was able to increase the accuracy of the predictions by a considerable amount on average.\n"
      ],
      "id": "c3d1ee18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Micro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Macro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))"
      ],
      "id": "bc795cee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
        "conf_df = pd.DataFrame(confusion_matrix, index=[f\"{i}\" for i in range(6)], columns=[f\"{i}\" for i in range(6)])\n",
        "heatmap = sns.heatmap(conf_df, annot=True, fmt=\"d\", linewidths=0.35, cmap=\"YlGnBu\")\n",
        "plt.title(f\"Model Predictions With {(np.sum(confusion_matrix.diagonal()) / y_test.shape[0]) * 100:.2f}% Accuracy\")"
      ],
      "id": "73059736",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, I decided to calculate the accuracy preformance on multiple samples of RandomForestClassifiers and DecisionTrees at the same time and plot them out in a line chart.\n"
      ],
      "id": "fe606d14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "Plot a graph that compares the two models, randomly generated with tuned hyperparameter models\n",
        "'''\n",
        "dt_results = []\n",
        "rf_results = []\n",
        "n_samples = 40\n",
        "indexes = [i for i in range(n_samples)]\n",
        "for i in indexes:\n",
        "    dt = DecisionTreeClassifier(max_depth=best_params_dt[\"max_depth\"], \n",
        "                   min_samples_leaf=best_params_dt[\"min_samples_leaf\"], criterion=best_params_dt[\"criterion\"])\n",
        "    dt.fit(X_train, y_train)\n",
        "    y_pred_dt = dt.predict(X_test)\n",
        "    \n",
        "    rf = RandomForestClassifier(n_estimators=300, \n",
        "                            max_depth=best_params_rf[\"max_depth\"], \n",
        "                            min_samples_leaf=best_params_rf[\"min_samples_leaf\"],\n",
        "                            criterion=best_params_rf[\"criterion\"])\n",
        "    rf.fit(X_train, y_train.values.ravel())\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    \n",
        "    confusion_matrix_dt = sklearn.metrics.confusion_matrix(y_test, y_pred_dt)\n",
        "    confusion_matrix_rf = sklearn.metrics.confusion_matrix(y_test, y_pred_rf)\n",
        "    \n",
        "    dt_results.append((np.sum(confusion_matrix_dt.diagonal()) / y_test.shape[0]) * 100)\n",
        "    rf_results.append((np.sum(confusion_matrix_rf.diagonal()) / y_test.shape[0]) * 100)\n",
        "\n",
        "plt.plot(indexes, dt_results, label=\"DT results\")\n",
        "plt.plot(indexes, rf_results, label=\"RF results\")\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Accuracy on Test Data in %\")\n",
        "plt.title(\"Accuracy Comparison Between DT and RF on Randomly Generated Models\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "9154e7bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Improvements\n",
        "\n",
        "Now that I've determined RandomForestClassifier as an overall better approach for this problem, I've included more ways to improve the current implementation.\n",
        "\n",
        "Earlier, I stated that `gender` may be a redudndant feature based on the correlation matrix, so I decided to drop that in the dataset when training the model.\n"
      ],
      "id": "bc4f150a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [i for i in range(2, 6)],\n",
        "    'min_samples_leaf': [2 ** i for i in range(0, 6)],\n",
        "    'criterion': [\"entropy\", \"gini\"]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search_rf = GridSearchCV(rf, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
        "grid_search_rf.fit(X_train.drop(['Gender_Encoded'], axis=1), y_train.values.ravel())\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params_rf)\n",
        "print(\"Best Score:\", grid_search_rf.best_score_)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=300, \n",
        "                            max_depth=best_params_rf[\"max_depth\"], \n",
        "                            min_samples_leaf=best_params_rf[\"min_samples_leaf\"],\n",
        "                            criterion=best_params_rf[\"criterion\"])\n",
        "rf.fit(X_train.drop(['Gender_Encoded'], axis=1), y_train.values.ravel())\n",
        "y_pred = rf.predict(X_test.drop(['Gender_Encoded'], axis=1))"
      ],
      "id": "424ef73e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
        "conf_df = pd.DataFrame(confusion_matrix, index=[f\"{i}\" for i in range(6)], columns=[f\"{i}\" for i in range(6)])\n",
        "heatmap = sns.heatmap(conf_df, annot=True, fmt=\"d\", linewidths=0.35, cmap=\"YlGnBu\")\n",
        "plt.title(f\"Model Predictions With {(np.sum(confusion_matrix.diagonal()) / y_test.shape[0]) * 100:.2f}% Accuracy (NO GENDER)\")"
      ],
      "id": "736afe8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Micro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Macro F1: \", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))"
      ],
      "id": "8bcebb97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that removing that feature, on average, didn't hurt the preformance of the overall model.\n",
        "\n",
        "Finally, below is a learning curve showing accuracy results in respect to the number of samples in the training set. This plot is heavily dependent on the random state of the generated RandomForestClassifier and its underlying DecisionTrees. Sometimes the model is overfitting, so I tried minimizing the hyperparameter values to make sure it mostly doesn't.\n"
      ],
      "id": "32880b0e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_sizes, train_scores, test_scores = learning_curve(rf, X_train, y_train.values.ravel(), cv=StratifiedKFold(n_splits=5))\n",
        "display = LearningCurveDisplay(train_sizes=train_sizes,\n",
        "    train_scores=train_scores, test_scores=test_scores, score_name=\"Score\")\n",
        "display.plot()\n",
        "plt.title(\"Learning Curve on RandomForestClassifer (NO GENDER)\")\n",
        "plt.show()"
      ],
      "id": "3d431928",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results and Conclusions\n",
        "\n",
        "After doing simple experimentation with these models, I have found that, on average, the RandomForestClassifier outpreforms just a singular DecisionTreeClassifier. There are several advantages to having a forest of DecisionTrees rather than a singular tree:\n",
        "\n",
        "* More generalizability due to the ensemble approach to this problem\n",
        "\n",
        "* Limits overfitting compared to a DT\n",
        "\n",
        "* DT has high variance and instability, so having a forest of those trees in a more collective approach would help get more opinions at least.\n",
        "\n",
        "Though there is more resource complexity with a forest, the benefits of using that over a DT is worth the tradeoff. \n"
      ],
      "id": "62c000a4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}